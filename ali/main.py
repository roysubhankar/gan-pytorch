import os
import numpy as np
import matplotlib.pyplot as plt
from argparse import ArgumentParser
from datetime import datetime

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.datasets as dset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision.utils as vutils
import torch.optim as optim
from torchvision.utils import save_image

from networks import Generator, Discriminator, Encoder

# custom weight initialization
def weight_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.01)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0.0)

def save_weights(model, path):
    torch.save(model.state_dict(), path)

def main(args, dataloader):
    # define the networks
    netG = Generator(ngf=args.ngf, nz=args.nz, nc=args.nc).cuda()
    netG.apply(weight_init)
    print(netG)

    netD = Discriminator(ndf=args.ndf, nc=args.nc, nz=args.nz).cuda()
    netD.apply(weight_init)
    print(netD)

    netE = Encoder(nc=args.nc, ngf=args.ngf, nz=args.nz).cuda()
    netE.apply(weight_init)
    print(netE)

    # define the loss criterion
    criterion = nn.BCELoss()

    # define the ground truth labels.
    real_label = 1  # for the real pair
    fake_label = 0  # for the fake pair

    # define the optimizers, one for each network
    netD_optimizer = optim.Adam(netD.parameters(), lr=args.lr, betas=(0.5, 0.999))
    netG_optimizer = optim.Adam([{'params': netG.parameters()},
                                 {'params': netE.parameters()}], lr=args.lr, betas=(0.5, 0.999))

    # Training loop
    iters = 0

    for epoch in range(args.num_epochs):
        # iterate through the dataloader
        for i, data in enumerate(dataloader, 0):
            real_images = data[0].cuda()
            bs = real_images.shape[0]

            noise1 = torch.Tensor(real_images.size()).normal_(0, 0.1 * (args.num_epochs - epoch) / args.num_epochs).cuda()
            noise2 = torch.Tensor(real_images.size()).normal_(0, 0.1 * (args.num_epochs - epoch) / args.num_epochs).cuda()

            # get the output from the encoder
            z_real = netE(real_images).view(bs, -1)
            mu, sigma = z_real[:, :args.nz], z_real[:, args.nz:]
            log_sigma = torch.exp(sigma)
            epsilon = torch.randn(bs, args.nz).cuda()
            # reparameterization trick
            output_z = mu + epsilon * log_sigma
            output_z = output_z.view(bs, -1, 1, 1)

            # get the output from the generator
            z_fake = torch.randn(bs, args.nz, 1, 1).cuda()
            d_fake = netG(z_fake)

            # get the output from the discriminator for the real pair
            out_real_pair = netD(real_images + noise1, output_z)

            # get the output from the discriminator for the fake pair
            out_fake_pair = netD(d_fake + noise2, z_fake)

            real_labels = torch.full((bs,), real_label).cuda()
            fake_labels = torch.full((bs,), fake_label).cuda()

            # compute the losses
            d_loss = criterion(out_real_pair, real_labels) + criterion(out_fake_pair, fake_labels)
            g_loss = criterion(out_real_pair, fake_labels) + criterion(out_fake_pair, real_labels)

            # update weights
            if g_loss.item() < 3.5:
                netD_optimizer.zero_grad()
                d_loss.backward(retain_graph=True)
                netD_optimizer.step()

            netG_optimizer.zero_grad()
            g_loss.backward()
            netG_optimizer.step()

            # print the training losses
            if iters % 10 == 0:
                print('[%3d/%d][%3d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x, z): %.4f\tD(G(z), z): %.4f'
                      % (epoch, args.num_epochs, i, len(dataloader), d_loss.item(), g_loss.item(),
                         out_real_pair.mean().item(), out_fake_pair.mean().item()))

            # visualize the samples generated by the G.
            if iters % 500 == 0:
                out_dir = os.path.join(args.log_dir, args.run_name, 'out/')
                os.makedirs(out_dir, exist_ok=True)
                save_image(d_fake.cpu()[:64, ], os.path.join(out_dir, str(iters).zfill(7) + '.png'),
                           nrow=8, normalize=True)
                # save reconstructions
                recons_dir = os.path.join(args.log_dir, args.run_name, 'recons/')
                os.makedirs(recons_dir, exist_ok=True)
                save_image(torch.cat([real_images.cpu()[:8], d_fake.cpu()[:8, ]], dim=3),
                           os.path.join(recons_dir, str(iters).zfill(7) + '.png'),
                           nrow=1, normalize=True)


            iters += 1

        # save weights
        save_dir = os.path.join(args.log_dir, args.run_name, 'weights')
        os.makedirs(save_dir, exist_ok=True)
        save_weights(netG, './%s/netG.pth' % (save_dir))
        save_weights(netE, './%s/netE.pth' % (save_dir))



if __name__ == '__main__':
    parser = ArgumentParser()
    parser.add_argument('--img_size', default=64, type=int, help='size of input image')
    parser.add_argument('--root_folder', type=str, help='path to the root folder')
    parser.add_argument('--batch_size', default=100, type=int, help='batch size')
    parser.add_argument('--nc', default=3, type=int, help='number of channels in input image')
    parser.add_argument('--ngf', default=64, type=int, help='number of generator features')
    parser.add_argument('--ndf', default=64, type=int, help='number of discriminator features')
    parser.add_argument('--nz', default='512', type=int, help='latent dimensions')
    parser.add_argument('--lr', default=1e-4, type=float, help='learning rate of the networks')
    parser.add_argument('--num_epochs', default=123, type=int, help='number of learning epochs')
    parser.add_argument('--log_dir', default='log', help='path to log directory')
    parser.add_argument('--comment', default=datetime.now().strftime('%d_%H-%M-%S'), type=str,
                        help='Comment to be appended to the model name to identify the run')
    parser.add_argument('--model_name', default='anime_small', type=str,
                        help='Name of the model you want to use.')
    args = parser.parse_args()
    args.run_name = '-'.join([args.model_name, args.comment])

    # create a set of transforms for the dataset
    dset_transforms = list()
    dset_transforms.append(transforms.Resize((args.img_size, args.img_size)))
    dset_transforms.append(transforms.ToTensor())
    dset_transforms.append(transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                                std=[0.5, 0.5, 0.5]))
    dset_transforms = transforms.Compose(dset_transforms)

    # create a dataset using ImageFolder of pytorch
    dataset = dset.ImageFolder(root=args.root_folder, transform=dset_transforms)

    # create a data loader
    dataloader = DataLoader(dataset, batch_size=args.batch_size, num_workers=4, shuffle=True, drop_last=True)

    main(args, dataloader)